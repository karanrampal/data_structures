Arrays:
1. Constant time O(1) access to read, write.
2. Row major indexing i.e. all elements of row 1 are followed by row 2 elements etc.
3. Column major indexing i.e. all elements of Column 1 are followed by all elements of Column 2 etc.
4. O(n) for add/remove elements in begining and middle. O(1) to add/remove at the end.
5. Elements are contiguous

Linked Lists:
1. Elements need not be contiguous.

Singly Linked Lists:
1. Contains Nodes which contains a) key b) next pointer
2. Possible Operations:
    pushfront O(1)
    topfront (return top item) O(1)
    popfront (remove front item) O(1)
    pushback O(n) if tail pointer exists then O(1)
    topback O(n) if tail pointer exists then O(1)
    popback O(n)
    find O(n)
    erase O(n)
    empty O(1)
    addafter O(1)
    addbefore O(n)

Double Linked Lists:
1. Contains Nodes which contains a) key b) next pointer c) prev pointer
2. Possible Operations:
    pushfront O(1)
    topfront (return top item) O(1)
    popfront (remove front item) O(1)
    pushback O(n) if tail pointer exists then O(1)
    topback O(n) if tail pointer exists then O(1)
    popback O(1)
    find O(n)
    erase O(n)
    empty O(1)
    addafter O(1)
    addbefore O(1)

Stacks:
1. Array implementation has some overhead because of the size of the array used which can be unused. Also they have a maximum size limit.
2. Linked list implementation has some fixed overhead because of storing pointers along with the values
3. Each operation is O(1) i.e. push, pop, top, empty

Queue:
1. Linked list implementation with tail pointer.
2. Array implementation we need to keep track of 2 indexes the enqueue index and the dequeue index. and make the array circular i.e. wrap back to idx 0 if reached end.
3. Array implementation has a max size limitation.
4. Each queue operation is O(1) i.e. enqueue, dequeue, empty

Tree:
1. Contains nodes which contain key, list of child nodes
2. Binary Tree each node has at max 2 nodes only. Contains nodes which contain key, left, right.
3. Binary Search Tree (BST) each left node is less than parent and each right node is greater than parent.
        5
    4        7
2        6        8
    3

Tree traversal:
1. Depth first e.g. usually implemented using recursion or if done iteratively then use stack
    a) in-order traversal (left, print, right). It is only for binary tree as for others it's not clear which is mid point. Sorted output.
    b) pre-order traversal (print, left, right). Parent printed first then children.
    c) post-order traversal (left, right, print). children printed first then parent. Like a stack.
2. Breadth first usually implemented using a queue

Priority Queue:
1. Binary min/max-heap are 2 types of priority queues. Min heap means value of parent is <= it's children.
2. Creating a heap from list is O(n) amortized (Technically its O(nlogn) but the call to siftdown is such that there is only one node below to swap so it is fast)
3. Insert in heap is O(logn), extractMin/Max is O(logn), getMin/Max is O(1)
4. We can use n-ary heap as well instead of binary heap, however the siftdown becomes O(d*log_base_d(n)) instead of O(logn) so not better than binary min/max heap.

Partial sorting:
1. From a larg array of n elements only find first k sorted elements.
2. Create binary min heap O(n) and extractmin k elements O(klogn) then if k is n/logn so the total complexity is O(n)

Union-find/Disjoint sets:
1. Possible operations are MakeSet O(1), Union O(logn), find O(logn)
2. With path compression all operations are O(1) or amortized O(log*n) which is nearly constant.
3. iterated logarithm log*n is the no. of times log needs to be applied to n before we get <= 1

Hash tables (maps, dict, set):
1. Converts objects (keys) in a set S to values in set V where |V| << |S|
2. Since the cardinality of V is less than S there are collisions so we have to design the hash function such that the probability of collision is small.
3. Can be implemented by an array of doubly linked lists.
4. Memory complexity is O(m+n) where n are the total objects and m is the number of buckets.
5. HasKey, Get, Set are all O(c+1) where c is the length of the longest chain.
7. We want to make c and m as small as possible to get fast operations, so better hash functions are needed.